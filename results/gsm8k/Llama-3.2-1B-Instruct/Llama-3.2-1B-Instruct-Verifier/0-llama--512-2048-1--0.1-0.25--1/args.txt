seed: 1234
benchmark: gsm8k
data_dir: ./data/evaluation/gsm8k
save_dir: ./results/gsm8k/Llama-3.2-1B-Instruct/Llama-3.2-1B-Instruct-Verifier/0-llama--512-2048-1--0.1-0.25--1
max_num_examples: None
max_num_examples_per_task: None
model_name_or_path: meta-llama/Llama-3.2-1B-Instruct
verifier_model_name_or_path: ./checkpoints/Llama-3.2-1B-Instruct-Verifier
load_in_8bit: False
no_cot: False
n_shot: 0
prompt_format: llama
prefix: 
use_chat_format: False
eval_pass_at_ks: [1]
max_input_tokens: 2048
max_new_tokens: 512
num_beams: 1
top_k: None
alpha: 0.1
beta: 0.25
num_workers: 4
micro_batch_size_per_gpu: 1
preprocessing_num_workers: 1
writer_batch_size: 1000
keep_in_memory: True
overwrite_cache: False
do_sample: False